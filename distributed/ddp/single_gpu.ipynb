{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据集\n",
    "\n",
    "这里我们模拟一个线性的数据集。 (input_shape=20) -> (output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DDPTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, size: int):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.data = [(torch.rand(20), torch.rand(1)) for _ in range(size)] \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义数据集接口和准备数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset():\n",
    "    \n",
    "    train_dataset = DDPTrainDataset(size=2096)\n",
    "    model = torch.nn.Linear(20, 1) \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "    return train_dataset, model, optimizer\n",
    "\n",
    "\n",
    "def prepare_dataloader(dataset: Dataset, batch_size: int):\n",
    "    \n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle = True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699\n",
      "[tensor([[0.4656, 0.2774, 0.6411, 0.4094, 0.2635, 0.0147, 0.5033, 0.6247, 0.3505,\n",
      "         0.4241, 0.1776, 0.9870, 0.8843, 0.2066, 0.5938, 0.5882, 0.4147, 0.4700,\n",
      "         0.2333, 0.1819],\n",
      "        [0.1698, 0.2924, 0.0185, 0.8407, 0.0124, 0.9079, 0.9204, 0.1655, 0.4217,\n",
      "         0.7464, 0.0678, 0.2419, 0.0433, 0.2892, 0.0292, 0.1639, 0.6973, 0.3199,\n",
      "         0.4906, 0.8398],\n",
      "        [0.5716, 0.3419, 0.5777, 0.0492, 0.5661, 0.3120, 0.7183, 0.2138, 0.2442,\n",
      "         0.6456, 0.5655, 0.1854, 0.9365, 0.3166, 0.9549, 0.5539, 0.3119, 0.2418,\n",
      "         0.2596, 0.9206]]), tensor([[0.4416],\n",
      "        [0.9753],\n",
      "        [0.1021]])]\n",
      "3\n",
      "[tensor([[0.3404, 0.9200, 0.2126, 0.5422, 0.8707, 0.9628, 0.0770, 0.2595, 0.2012,\n",
      "         0.6956, 0.4363, 0.3337, 0.1730, 0.2882, 0.7458, 0.2677, 0.2670, 0.3767,\n",
      "         0.3765, 0.6355],\n",
      "        [0.5410, 0.7625, 0.4727, 0.0571, 0.9136, 0.3922, 0.6478, 0.9339, 0.9876,\n",
      "         0.5733, 0.1305, 0.4316, 0.7166, 0.4530, 0.3302, 0.9528, 0.6323, 0.2309,\n",
      "         0.1198, 0.0529],\n",
      "        [0.0457, 0.9411, 0.1655, 0.8873, 0.9736, 0.7094, 0.3229, 0.9289, 0.5637,\n",
      "         0.5846, 0.2724, 0.2362, 0.2759, 0.2403, 0.2229, 0.8095, 0.1444, 0.0898,\n",
      "         0.7735, 0.4378]]), tensor([[0.9428],\n",
      "        [0.6122],\n",
      "        [0.8652]])]\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "train_dataset, model, optimizer = get_train_dataset()\n",
    "\n",
    "d = prepare_dataloader(train_dataset, batch_size = 3)\n",
    "\n",
    "print(len(d))\n",
    "print(next(iter(d)))\n",
    "print(len(next(iter(d))[0]))\n",
    "\n",
    "for data in d:\n",
    "    print(data)\n",
    "    print(data[0].shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, gpu_id, model,  train_data, optimizer, save_every: int):\n",
    "        super().__init__()\n",
    "        self.gpu_id = gpu_id\n",
    "        self.model = model.to(gpu_id) \n",
    "        self.train_data = train_data\n",
    "        self.optimizer = optimizer\n",
    "        self.save_every = save_every\n",
    "    \n",
    "    def _run_batch(self, source, target):\n",
    "        \n",
    "        output = self.model(source)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def _run_epoch(self, epoch):\n",
    "        \n",
    "        bs = len(next(iter(self.train_data))[0])\n",
    "        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {bs} | Steps: {len(self.train_data)}\")\n",
    "\n",
    "        input_size = 0\n",
    "        \n",
    "        for data in self.train_data:\n",
    "            source, target = data\n",
    "            source = source.to(self.gpu_id)\n",
    "            target = target.to(self.gpu_id)\n",
    "            loss = self._run_batch(source, target)\n",
    "            \n",
    "            input_size += source.shape[0]\n",
    "        print(f\"Epoch {epoch} completed, Handle_Input_Size = {input_size}, loss = {loss}\")\n",
    "    \n",
    "    def _save_model(self, epoch):\n",
    "        path = f\"model_epoch_{epoch}.pth\"\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    \n",
    "    def train(self, max_epochs: int):\n",
    "        for epoch in range(max_epochs):\n",
    "            self._run_epoch(epoch)\n",
    "            \n",
    "            if epoch % self.save_every == 0:\n",
    "                self._save_model(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPUcuda:0] Epoch 0 | Batchsize: 32 | Steps: 66\n",
      "Epoch 0 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 1 | Batchsize: 32 | Steps: 66\n",
      "Epoch 1 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 2 | Batchsize: 32 | Steps: 66\n",
      "Epoch 2 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 3 | Batchsize: 32 | Steps: 66\n",
      "Epoch 3 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 4 | Batchsize: 32 | Steps: 66\n",
      "Epoch 4 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 5 | Batchsize: 32 | Steps: 66\n",
      "Epoch 5 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 6 | Batchsize: 32 | Steps: 66\n",
      "Epoch 6 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 7 | Batchsize: 32 | Steps: 66\n",
      "Epoch 7 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 8 | Batchsize: 32 | Steps: 66\n",
      "Epoch 8 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 9 | Batchsize: 32 | Steps: 66\n",
      "Epoch 9 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 10 | Batchsize: 32 | Steps: 66\n",
      "Epoch 10 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 11 | Batchsize: 32 | Steps: 66\n",
      "Epoch 11 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 12 | Batchsize: 32 | Steps: 66\n",
      "Epoch 12 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 13 | Batchsize: 32 | Steps: 66\n",
      "Epoch 13 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 14 | Batchsize: 32 | Steps: 66\n",
      "Epoch 14 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 15 | Batchsize: 32 | Steps: 66\n",
      "Epoch 15 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 16 | Batchsize: 32 | Steps: 66\n",
      "Epoch 16 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 17 | Batchsize: 32 | Steps: 66\n",
      "Epoch 17 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 18 | Batchsize: 32 | Steps: 66\n",
      "Epoch 18 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 19 | Batchsize: 32 | Steps: 66\n",
      "Epoch 19 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 20 | Batchsize: 32 | Steps: 66\n",
      "Epoch 20 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 21 | Batchsize: 32 | Steps: 66\n",
      "Epoch 21 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 22 | Batchsize: 32 | Steps: 66\n",
      "Epoch 22 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 23 | Batchsize: 32 | Steps: 66\n",
      "Epoch 23 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 24 | Batchsize: 32 | Steps: 66\n",
      "Epoch 24 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 25 | Batchsize: 32 | Steps: 66\n",
      "Epoch 25 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 26 | Batchsize: 32 | Steps: 66\n",
      "Epoch 26 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 27 | Batchsize: 32 | Steps: 66\n",
      "Epoch 27 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 28 | Batchsize: 32 | Steps: 66\n",
      "Epoch 28 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 29 | Batchsize: 32 | Steps: 66\n",
      "Epoch 29 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 30 | Batchsize: 32 | Steps: 66\n",
      "Epoch 30 completed, Handle_Input_Size = 2096, loss = -0.0\n",
      "[GPUcuda:0] Epoch 31 | Batchsize: 32 | Steps: 66\n",
      "Epoch 31 completed, Handle_Input_Size = 2096, loss = -0.0\n"
     ]
    }
   ],
   "source": [
    "def main(device, total_epochs, save_every, batch_szie):\n",
    "    train_dataset, model, optimizer = get_train_dataset()\n",
    "    model = model\n",
    "    train_data = prepare_dataloader(train_dataset, batch_size = batch_szie)\n",
    "    trainer = Trainer(device, model, train_data, optimizer, save_every)\n",
    "    trainer.train(total_epochs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--total_epochs', type=int, help='total epochs to train')\n",
    "    parser.add_argument('--save_every', type=int, help='save model every n epochs')\n",
    "    parser.add_argument('--batch_size', type=int, help='batch size on each device', default=32)\n",
    "    \n",
    "    \n",
    "    args = parser.parse_args(['--total_epochs', '32', '--save_every', '10', '--batch_size', '32'])\n",
    "    \n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    main(device, args.total_epochs, args.save_every, args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
