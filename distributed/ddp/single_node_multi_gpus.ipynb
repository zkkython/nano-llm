{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "class DDPTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, size: int):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.data = [(torch.rand(20), torch.rand(1)) for _ in range(size)] \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 创建初始化DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def ddp_setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    torch.cuda.set_device(rank)\n",
    "    init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_objs():\n",
    "    train_set = DDPTrainDataset(2048)  # load your dataset\n",
    "    model = torch.nn.Linear(20, 1)  # load your model\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    return train_set, model, optimizer\n",
    "\n",
    "\n",
    "def prepare_dataloader(dataset: Dataset, batch_size: int):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        sampler=DistributedSampler(dataset)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_data: DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        gpu_id: int,\n",
    "        save_every: int,\n",
    "    ) -> None:\n",
    "        self.gpu_id = gpu_id\n",
    "        self.model = model.to(gpu_id)\n",
    "        self.train_data = train_data\n",
    "        self.optimizer = optimizer\n",
    "        self.save_every = save_every\n",
    "        self.model = DDP(model, device_ids=[gpu_id])\n",
    "\n",
    "    def _run_batch(self, source, targets):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(source)\n",
    "        loss = F.cross_entropy(output, targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def _run_epoch(self, epoch):\n",
    "        b_sz = len(next(iter(self.train_data))[0])\n",
    "        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n",
    "        self.train_data.sampler.set_epoch(epoch)\n",
    "        for source, targets in self.train_data:\n",
    "            source = source.to(self.gpu_id)\n",
    "            targets = targets.to(self.gpu_id)\n",
    "            self._run_batch(source, targets)\n",
    "\n",
    "    def _save_checkpoint(self, epoch):\n",
    "        ckp = self.model.module.state_dict()\n",
    "        PATH = \"checkpoint.pt\"\n",
    "        torch.save(ckp, PATH)\n",
    "        print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n",
    "\n",
    "    def train(self, max_epochs: int):\n",
    "        for epoch in range(max_epochs):\n",
    "            self._run_epoch(epoch)\n",
    "            if self.gpu_id == 0 and epoch % self.save_every == 0:\n",
    "                self._save_checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(rank: int, world_size: int, save_every: int, total_epochs: int, batch_size: int):\n",
    "    ddp_setup(rank, world_size)\n",
    "    dataset, model, optimizer = load_train_objs()\n",
    "    train_data = prepare_dataloader(dataset, batch_size)\n",
    "    trainer = Trainer(model, train_data, optimizer, rank, save_every)\n",
    "    trainer.train(total_epochs)\n",
    "    destroy_process_group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/kason/anaconda3/envs/torch/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kason/anaconda3/envs/torch/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'main' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProcessExitedException\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m args = parser.parse_args(args=args_list)\n\u001b[32m     20\u001b[39m world_size = torch.cuda.device_count()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m mp.spawn(main, args=(world_size, args.save_every, args.total_epochs, args.batch_size), nprocs=world_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:328\u001b[39m, in \u001b[36mspawn\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method)\u001b[39m\n\u001b[32m    322\u001b[39m     msg = (\n\u001b[32m    323\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    326\u001b[39m     )\n\u001b[32m    327\u001b[39m     warnings.warn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_processes(fn, args, nprocs, join, daemon, start_method=\u001b[33m\"\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:284\u001b[39m, in \u001b[36mstart_processes\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method)\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context.join():\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/torch/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:192\u001b[39m, in \u001b[36mProcessContext.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[32m    185\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (error_index, name),\n\u001b[32m    186\u001b[39m             error_index=error_index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    189\u001b[39m             signal_name=name,\n\u001b[32m    190\u001b[39m         )\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[32m    193\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (error_index, exitcode),\n\u001b[32m    194\u001b[39m             error_index=error_index,\n\u001b[32m    195\u001b[39m             error_pid=failed_process.pid,\n\u001b[32m    196\u001b[39m             exit_code=exitcode,\n\u001b[32m    197\u001b[39m         )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.error_files[error_index], \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[32m    200\u001b[39m     original_trace = pickle.load(fh)\n",
      "\u001b[31mProcessExitedException\u001b[39m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='simple distributed training job')\n",
    "    parser.add_argument('--total_epochs', type=int, help='Total epochs to train the model')\n",
    "    parser.add_argument('--save_every', type=int, help='How often to save a snapshot')\n",
    "    parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')\n",
    "    \n",
    "    args_list = [\n",
    "        '--total_epochs',\n",
    "        '32',\n",
    "        '--save_every',\n",
    "        '10',\n",
    "        '--batch_size',\n",
    "        '32'\n",
    "        \n",
    "    ]\n",
    "    args = parser.parse_args(args=args_list)\n",
    "\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(main, args=(world_size, args.save_every, args.total_epochs, args.batch_size), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
